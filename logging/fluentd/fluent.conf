# FlowEx Production Logging Configuration
# =======================================
# 
# Centralized logging configuration for FlowEx trading platform
# Created by arkSong (arksong2018@gmail.com)

# Input sources
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker.*
</source>

# Docker container logs
<source>
  @type tail
  @id flowex_services
  path /var/log/containers/flowex-*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  format json
  time_format %Y-%m-%dT%H:%M:%S.%NZ
</source>

# System logs
<source>
  @type systemd
  @id systemd_input
  tag systemd
  path /var/log/journal
  matches [{ "_SYSTEMD_UNIT": "docker.service" }]
  read_from_head true
  strip_underscores true
</source>

# Nginx access logs
<source>
  @type tail
  @id nginx_access
  path /var/log/nginx/access.log
  pos_file /var/log/fluentd-nginx-access.log.pos
  tag nginx.access
  format nginx
</source>

# Nginx error logs
<source>
  @type tail
  @id nginx_error
  path /var/log/nginx/error.log
  pos_file /var/log/fluentd-nginx-error.log.pos
  tag nginx.error
  format /^(?<time>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?<log_level>\w+)\] (?<pid>\d+).(?<tid>\d+): (?<message>.*)$/
</source>

# PostgreSQL logs
<source>
  @type tail
  @id postgresql
  path /var/log/postgresql/postgresql-*.log
  pos_file /var/log/fluentd-postgresql.log.pos
  tag postgresql
  format /^(?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.\d{3} \w+) \[(?<pid>\d+)\] (?<level>\w+):  (?<message>.*)$/
  time_format %Y-%m-%d %H:%M:%S.%L %Z
</source>

# Redis logs
<source>
  @type tail
  @id redis
  path /var/log/redis/redis-server.log
  pos_file /var/log/fluentd-redis.log.pos
  tag redis
  format /^(?<pid>\d+):(?<role>\w) (?<time>\d{2} \w{3} \d{4} \d{2}:\d{2}:\d{2}.\d{3}) (?<level>.) (?<message>.*)$/
  time_format %d %b %Y %H:%M:%S.%L
</source>

# Filters for log processing
<filter docker.**>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

# Add Kubernetes metadata
<filter kubernetes.**>
  @type kubernetes_metadata
  @id kubernetes_metadata
</filter>

# Parse FlowEx service logs
<filter docker.flowex-*>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</filter>

# Add service identification
<filter docker.flowex-*>
  @type record_transformer
  <record>
    service_name ${tag_parts[1]}
    environment production
    platform flowex
  </record>
</filter>

# Security log filtering
<filter **>
  @type grep
  <regexp>
    key message
    pattern /(?i)(password|token|secret|key|auth)/
  </regexp>
  <exclude>
    key level
    pattern /^(DEBUG|TRACE)$/
  </exclude>
</filter>

# Error log enhancement
<filter **>
  @type record_transformer
  enable_ruby true
  <record>
    severity ${record["level"] || record["log_level"] || "INFO"}
    timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%LZ')}
    source_host "#{Socket.gethostname}"
  </record>
</filter>

# Trading-specific log processing
<filter docker.flowex-trading-service>
  @type record_transformer
  <record>
    log_type trading
    business_critical true
  </record>
</filter>

# Authentication log processing
<filter docker.flowex-auth-service>
  @type record_transformer
  <record>
    log_type authentication
    security_relevant true
  </record>
</filter>

# Output configurations
# Elasticsearch for log storage and search
<match **>
  @type elasticsearch
  @id elasticsearch_output
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix flowex
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name _doc
  tag_key @log_name
  flush_interval 10s
  
  # Buffer configuration
  <buffer>
    @type file
    path /var/log/fluentd-buffers/elasticsearch.buffer
    flush_mode interval
    retry_type exponential_backoff
    flush_thread_count 2
    flush_interval 5s
    retry_forever
    retry_max_interval 30
    chunk_limit_size 2M
    queue_limit_length 8
    overflow_action block
  </buffer>
</match>

# Copy critical logs to separate storage
<match docker.flowex-trading-service docker.flowex-auth-service>
  @type copy
  
  # Primary storage
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix flowex-critical
    include_tag_key true
  </store>
  
  # Backup storage
  <store>
    @type file
    path /var/log/flowex-critical/critical.%Y%m%d.log
    time_slice_format %Y%m%d
    time_slice_wait 10m
    compress gzip
  </store>
  
  # Real-time alerting
  <store>
    @type http
    endpoint http://alertmanager:9093/api/v1/alerts
    http_method post
    <format>
      @type json
    </format>
    <buffer>
      flush_interval 1s
    </buffer>
  </store>
</match>

# Metrics output for monitoring
<match fluent.**>
  @type prometheus
  <metric>
    name fluentd_input_status_num_records_total
    type counter
    desc The total number of incoming records
    <labels>
      tag ${tag}
      hostname ${hostname}
    </labels>
  </metric>
</match>
